{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quick draw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1M0lD0zVAyD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47954b80-a8e5-402d-edaa-31b5d5b027db"
      },
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "print(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No0_6e5HXjca",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "15f2d8b4-af56-481b-b863-a85965690a92"
      },
      "source": [
        "# !pip install gsutil\n",
        "!chmod 777 ./drive/My\\ Drive/Colab\\ Notebooks/data.sh\n",
        "!./drive/My\\ Drive/Colab\\ Notebooks/data.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/ant.npy...\n",
            "/ [1/1 files][ 93.2 MiB/ 93.2 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/93.2 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/bear.npy...\n",
            "- [1/1 files][100.8 MiB/100.8 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/100.8 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/camel.npy...\n",
            "/ [1/1 files][ 90.8 MiB/ 90.8 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/90.8 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/cat.npy...\n",
            "- [1/1 files][ 92.1 MiB/ 92.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/92.1 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/circle.npy...\n",
            "/ [1/1 files][ 91.9 MiB/ 91.9 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/91.9 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/cow.npy...\n",
            "/ [1/1 files][ 92.0 MiB/ 92.0 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/92.0 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/crocodile.npy...\n",
            "| [1/1 files][ 95.6 MiB/ 95.6 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/95.6 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/dog.npy...\n",
            "/ [1/1 files][113.8 MiB/113.8 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/113.8 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/elephant.npy...\n",
            "- [1/1 files][ 94.9 MiB/ 94.9 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/94.9 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/face.npy...\n",
            "\\ [1/1 files][120.9 MiB/120.9 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/120.9 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/fence.npy...\n",
            "- [1/1 files][ 96.8 MiB/ 96.8 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/96.8 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/giraffe.npy...\n",
            "\\ [1/1 files][ 95.1 MiB/ 95.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/95.1 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/grass.npy...\n",
            "- [1/1 files][ 92.0 MiB/ 92.0 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/92.0 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/hedgehog.npy...\n",
            "| [1/1 files][ 90.1 MiB/ 90.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/90.1 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/horse.npy...\n",
            "| [1/1 files][133.3 MiB/133.3 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/133.3 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/monkey.npy...\n",
            "/ [1/1 files][ 95.4 MiB/ 95.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/95.4 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/pig.npy...\n",
            "| [1/1 files][139.6 MiB/139.6 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/139.6 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/radio.npy...\n",
            "\\ [1/1 files][101.5 MiB/101.5 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/101.5 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/rhinoceros.npy...\n",
            "- [1/1 files][140.9 MiB/140.9 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/140.9 MiB.                                    \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/sheep.npy...\n",
            "- [1/1 files][ 94.3 MiB/ 94.3 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/94.3 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/snake.npy...\n",
            "- [1/1 files][ 91.4 MiB/ 91.4 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/91.4 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/square.npy...\n",
            "\\ [1/1 files][ 93.6 MiB/ 93.6 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/93.6 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/squiggle.npy...\n",
            "| [1/1 files][ 88.6 MiB/ 88.6 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/88.6 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/stereo.npy...\n",
            "/ [1/1 files][ 91.6 MiB/ 91.6 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/91.6 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/stove.npy...\n",
            "/ [1/1 files][ 87.1 MiB/ 87.1 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/87.1 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/suitcase.npy...\n",
            "/ [1/1 files][ 94.5 MiB/ 94.5 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/94.5 MiB.                                     \n",
            "Copying gs://quickdraw_dataset/full/numpy_bitmap/tiger.npy...\n",
            "| [1/1 files][ 90.5 MiB/ 90.5 MiB] 100% Done                                    \n",
            "Operation completed over 1 objects/90.5 MiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3AXibSW7xze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category = [\"ant\",\n",
        "       \"bear\",\n",
        "       \"camel\",\n",
        "       \"cat\",\n",
        "       \"circle\",\n",
        "       \"cow\",\n",
        "       \"crocodile\",\n",
        "       \"dog\",\n",
        "       \"elephant\", \n",
        "       \"face\",\n",
        "       \"fence\",\n",
        "       \"giraffe\",\n",
        "       \"grass\",\n",
        "       \"hedgehog\",\n",
        "       \"horse\",\n",
        "       \"monkey\", \n",
        "       \"pig\",\n",
        "       \"radio\", \n",
        "       \"rhinoceros\",\n",
        "       \"sheep\",\n",
        "       \"snake\",\n",
        "       \"square\",\n",
        "       \"squiggle\",\n",
        "       \"stereo\",\n",
        "       \"stove\",\n",
        "       \"suitcase\",\n",
        "       \"tiger\"\n",
        "       ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpbwzeDt7NIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import urllib\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "DOWNLOAD_ROOT = \"gs://quickdraw_dataset/full/numpy_bitmap/\"\n",
        "DRAWING_PATH = os.path.join(\"datasets\", \"drawings\")\n",
        "DRAWING_URL = DOWNLOAD_ROOT + \"datasets/drawings/\"\n",
        "IMAGE_SIZE = 28\n",
        "CAT_NUM = len(category)\n",
        "\n",
        "# def fetch_drawing_data(drawing_url=DRAWING_URL, drawing_path=DRAWING_PATH):\n",
        "#     os.makedirs(drawing_path, exist_ok=True)\n",
        "#     for c in category:\n",
        "#       filename = c + \".npy\"\n",
        "#       filepath = os.path.join(drawing_path, filename)\n",
        "#       downloading_file = DOWNLOAD_ROOT + filename\n",
        "#       if not os.path.exists(filepath):\n",
        "#         print(downloading_file)\n",
        "#         # urllib.request.urlretrieve(downloading_file, filepath)\n",
        "#         !gsutil -m cp downloading_file filepath\n",
        "#       else:\n",
        "#         os.remove(filepath);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvVKxQw2s4vW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_dataset(data, name_prefix, idx):\n",
        "    drawing_dir = os.path.join(DRAWING_PATH, name_prefix)\n",
        "    os.makedirs(drawing_dir, exist_ok=True)\n",
        "    path_format = os.path.join(drawing_dir, \"{}_{}.npy\")\n",
        "    npy_file = path_format.format(name_prefix, category[idx])\n",
        "    if not os.path.exists(npy_file):\n",
        "      np.save(npy_file, data)\n",
        "    return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcfQ5MtfakRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_file_path(select, drawing_path=DRAWING_PATH):\n",
        "  all_files = sorted(glob.glob(os.path.join(drawing_path, select, '*.npy')))\n",
        "  return all_files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BCBYu9oakMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(drawing_path=DRAWING_PATH, ratio = 0.2):\n",
        "  all_files = sorted(glob.glob(os.path.join(drawing_path, '*.npy')))\n",
        "  \n",
        "  #load each data file \n",
        "  for idx, file in enumerate(all_files):\n",
        "      data = np.load(file)\n",
        "      labels = np.full(data.shape[0], idx)\n",
        "\n",
        "      combined = np.c_[data,labels]\n",
        "      X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
        "          combined, labels.reshape(-1, 1), random_state=42)\n",
        "      save_dataset(X_test, \"test\", idx)\n",
        "      X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "        X_train_full, y_train_full, random_state=42)\n",
        "      save_dataset(X_train, \"train\", idx)\n",
        "      save_dataset(X_valid, \"valid\", idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTe3WXeQXJsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(drawing_path=DRAWING_PATH, vfold_ratio=0.2, max_items_per_class= 20000):\n",
        "  all_files = load_file_path(\"\")\n",
        "  \n",
        "  #initialize variables \n",
        "  x = np.empty([0, 784])\n",
        "  y = np.empty([0])\n",
        "\n",
        "  #load each data file \n",
        "  for idx, file in enumerate(all_files):\n",
        "      data = np.load(file)\n",
        "      data = data[0: max_items_per_class, :]\n",
        "      labels = np.full(data.shape[0], idx)\n",
        "\n",
        "      x = np.concatenate((x, data), axis=0)\n",
        "      y = np.append(y, labels)\n",
        "  data = None\n",
        "  labels = None\n",
        "\n",
        "  #separate into training and testing \n",
        "  X_train, X_test, y_train, y_test = train_test_split(\n",
        "      x, y, test_size=vfold_ratio, shuffle=True, random_state=42)\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5oE4xWIQkFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_origin, X_test_origin, y_train_origin, y_test_origin = load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRgF4HwnbSAx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.copy(X_train_origin)\n",
        "X_test = np.copy(X_test_origin)\n",
        "y_train = np.copy(y_train_origin)\n",
        "y_test = np.copy(y_test_origin)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkbWESrGUWQl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b382653f-a616-4a97-e295-f9913a856eef"
      },
      "source": [
        "print(len(X_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "432000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aACttQ5pakXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d05744b4-9a16-49a6-d9fd-da9cfdfd9083"
      },
      "source": [
        "file = os.path.join(DRAWING_PATH, \"ant.npy\")\n",
        "data = np.load(file)\n",
        "data = data.reshape(data.shape[0], IMAGE_SIZE, IMAGE_SIZE).astype('float32')\n",
        "data /= 255.0\n",
        "plt.imshow(data[3], cmap=\"Greys\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f64343c2ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiGgJ-5FZMs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape and normalize\n",
        "# x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "# x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "# x_train /= 255.0\n",
        "# x_test /= 255.0\n",
        "\n",
        "# # Convert class vectors to class matrices\n",
        "# y_train = keras.utils.to_categorical(y_train, 27)\n",
        "# y_test = keras.utils.to_categorical(y_test, 27)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4N3MNyoiXKT0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1).astype('float32')\n",
        "X_test = X_test.reshape(X_test.shape[0], IMAGE_SIZE, IMAGE_SIZE, 1).astype('float32')\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0\n",
        "y_train = keras.utils.to_categorical(y_train)\n",
        "y_test = keras.utils.to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb7APBdoXi79",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48daf476-38c5-40f6-e36e-d60f4a4d89d8"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(108000, 27)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0AMn7h2Ykcg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a12352c4-0e99-4d2d-8dfa-b6049f08d12e"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(432000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVdwxvIKakJx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "9a9f212f-88a9-4332-8886-2d2f94b15a2c"
      },
      "source": [
        "# Define model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=X_train.shape[1:], activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(keras.layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dense(27, activation='softmax')) \n",
        "# Train model\n",
        "adam = tf.optimizers.Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=adam,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 27)                3483      \n",
            "=================================================================\n",
            "Total params: 100,635\n",
            "Trainable params: 100,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vO56jFIa1kj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "outputId": "683101e6-2ce8-44ce-92fc-3d3fbb4b9a5f"
      },
      "source": [
        "model.fit(x = X_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1519/1519 - 9s - loss: 1.2584 - top_k_categorical_accuracy: 0.8890 - val_loss: 0.9610 - val_top_k_categorical_accuracy: 0.9333\n",
            "Epoch 2/5\n",
            "1519/1519 - 9s - loss: 0.8874 - top_k_categorical_accuracy: 0.9403 - val_loss: 0.8666 - val_top_k_categorical_accuracy: 0.9423\n",
            "Epoch 3/5\n",
            "1519/1519 - 9s - loss: 0.7969 - top_k_categorical_accuracy: 0.9483 - val_loss: 0.7797 - val_top_k_categorical_accuracy: 0.9484\n",
            "Epoch 4/5\n",
            "1519/1519 - 9s - loss: 0.7443 - top_k_categorical_accuracy: 0.9528 - val_loss: 0.7445 - val_top_k_categorical_accuracy: 0.9522\n",
            "Epoch 5/5\n",
            "1519/1519 - 9s - loss: 0.7074 - top_k_categorical_accuracy: 0.9561 - val_loss: 0.7132 - val_top_k_categorical_accuracy: 0.9542\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f642038b780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "omRRPMK6hAGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d93e19b6-53e3-4713-cbe6-9ecdc003d7e6"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 95.33%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "265u5QeHg1S3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras_3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BeFvOp3akPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def npy_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
        "                       n_read_threads=None, shuffle_buffer_size=10000,\n",
        "                       n_parse_threads=5, batch_size=32):\n",
        "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
        "    # for element in dataset:\n",
        "    #   print(element)\n",
        "    # dataset = tf.data.Dataset.from_tensor_slices(filepaths)\n",
        "    labeled_ds = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    # dataset = dataset.interleave(\n",
        "    #     lambda filepath: tf.data.TextLineDataset(filepath),\n",
        "    #     cycle_length=n_readers, num_parallel_calls=n_read_threads)\n",
        "    # dataset = dataset.shuffle(shuffle_buffer_size)\n",
        "    # dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
        "    # dataset = dataset.batch(batch_size)\n",
        "    return dataset.prefetch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36GtXPVkiMl_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjiwoG-2iMjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBZwk7aRiMco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5db3_ZmiMXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09nZVWUViMTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcT2nnNYTLre",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8igwx6sZ7om",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGOc6qokZ7nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIZixBZuZ7kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu36myiXZ7hI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXRZADvcZ7dV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdouiKi2Z7ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcWFNJdGZ7XI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LLcZZz-Z7UC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}