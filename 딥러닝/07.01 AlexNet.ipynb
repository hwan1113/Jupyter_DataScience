{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "a7fb04d97e0940ec8b6ac82443c76d20"
   },
   "source": [
    "# AlexNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "50c27c275ea349a4a5f5d78a87c3621f"
   },
   "source": [
    "[이미지넷](http://www.image-net.org/)에서 주관하는 ILSVRC (Large Scale Visual Recognition Competition) 이라는 대회에서, 2012년 제프리 힌튼 교수팀의 AlexNet이 top 5 test error(5개의 예측값 중에 정답이 없는 경우) 기준 15.4%를 기록해 2위(26.2%)를 큰 폭으로 이기고 1위를 차지했다. 이 대회는 1000개의 클래스를 가진 120만장의 이미지를 학습하고 15만장의 이미지로 테스트하여 정답률을 겨루는 대회이다. \n",
    "AlexNet의 등장은 딥러닝, 특히 CNN이 본격적으로 주목 받게되는 계기가 되었고 여기서 소개된 ReLU, Dropout 등은 지금도 표준으로 사용되고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "2a7a4c1808104695bc93f44faf6d183c"
   },
   "source": [
    "## AlexNet 구조 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "173959c8523c4a07870bc4cadce6771a"
   },
   "source": [
    "AlexNet의 구조는 5개의 컨볼루션 층(convolution layer), 3개의 fully connected layer로 이루어져있고, 마지막 레이어의 소프트맥스 함수를 사용하여 예측을 하게된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "d391b26fb14c40119e8234e34f1b54e8"
   },
   "source": [
    "#### AlexNet \n",
    "| 유형 |입력 크기 | 출력 크기 | 커널 크기 | 스트라이드 |활성화함수|\n",
    "|:--|:------:|:-------:|:-------:|:-------:|:------:|\n",
    "|**입력**|(224,224,3)| ||||\n",
    "|**Conv**|(224,224,3)|(56,56,96)|(11,11)|4|ReLU|\n",
    "|**Conv**|(56,56,96)|(56,56,256)|(5,5)|1|ReLU|\n",
    "|**LRN**||||||\n",
    "|**maxpool**|(56,56,256)|(27, 27, 256)|(3,3)|2||\n",
    "|**Conv**|(27, 27, 256)|(27, 27, 384)|(3,3)|1|ReLU|\n",
    "|**LRN**||||||\n",
    "|**maxpool**|(27, 27, 384)|(13, 13, 384)|(3,3)|2||\n",
    "|**Conv**|(13, 13, 384)|(13, 13, 384)|(3,3)|1|ReLcU|\n",
    "|**Conv**|(13, 13, 384)|(13, 13, 256)|(3,3)|1|ReLU|\n",
    "|**maxpool**|(13, 13, 256)|(6,6,256)|(3,3)|2||\n",
    "|**FCN**|(9216)|(4096)|||ReLu|\n",
    "|**FCN**|(4096)|(4096)|||ReLu|\n",
    "|**FCN**|(4096)|(1000)|||softmax|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "4a594ec426e649bea5bcbd4ca407c69a",
    "sidetitle": true
   },
   "source": [
    "표 57.1 : AlexNet 구조 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "7089c12f0c8445bd939f968eaa2a28bb"
   },
   "source": [
    "## AlexNet의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "a1d49e8f1c51469eb38b46182e5d33ce"
   },
   "source": [
    "1. 활성화 함수 \n",
    "\n",
    "  AlexNet에서는 기존에 사용하던 시그모이드 함수나 하이퍼탄젠트 함수 대신에 렐루 함수(ReLU)를 사용한다. 시그모이드, 하이퍼탄젠트 함수를 사용했을 때 보다, 학습속도가 6배 가량 빨랐고(논문 주장), 지수 연산 처럼 연산량이 꽤 드는 작업이 없어 컴퓨터 자원을 많이 절약했으며, 그레디언트가 더 잘 보존되었다. AlexNet에서는 마지막 층을 제외하고는 모두 렐루 함수를 사용했다. <br>\n",
    "\n",
    "2. GPU를 활용한 병렬 처리 \n",
    "\n",
    " AlexNet 저자들이 사용한 GPU모델은 GTX-580 3GB이다. 네트워크를 학습시키기엔 메모리에 한계가 있었기 때문에, 두 대의 GPU를 병렬 처리하여 사용하였다. 이 당시에는 학습을 90 에포크를 수행하는데, 5~6일이 소요되었다고 한다. \n",
    "\n",
    "3. LRN(Local Response Normalization)\n",
    "\n",
    " 활성화 함수로 렐루 함수를 사용했을 때, 또 하나의 장점은 시그모이드나 하이퍼탄젠트 함수에서와 달리 결과값이 양수에 한해서는 막히지 않았기 때문에 입력하는 데이터에 대한 정규화 과정이 꼭 필요하지 않다. 그럼에도 양수 방향으로 무한히 커질 가능성이 있어서 너무 큰 값이 주변 값들을 무시하게 할 수도 있기 때문에 정규화과정을 수행하는게 일반적인 관점(generalization)에서 좋다. \n",
    "\n",
    "    * LRN\n",
    "$$\n",
    "b_{x,y}^i = \\dfrac{a_{x,y}^i}{ \\left (k + \\alpha \\displaystyle\\sum^{min(N-1, i+n/2)}_{j=max(0,i-n/2)}(a_{x,y}^j)^2 \\right )^{\\beta}}\n",
    "$$\n",
    "위 식에서 $a_{x,y}^i$ 는 이미지의 $x, y$ 좌표에서의 $i$ 번째 필터를 의미한다. 그리고 $N$은 필터의 갯수를 의미한다. $k, n, \\alpha, \\beta$는 하이퍼 파라미터로 AlexNet에서는 각각 $k=2, n=5, \\alpha=10^{-4}, \\beta=0.75$로 설정했다. 예를 들어, 5번째 필터의 결과값은 3 ~ 7번째 결과값으로 정규화한다.  \n",
    "\n",
    "4. Overlapping pooling \n",
    "\n",
    "  기존의 풀링(pooling) 방식은 커널 크기를 2x2로 하고, 스트라이드(stride)를 2로 설정하여 이미지의 크기를 반으로 줄였다. AlexNet에서는 이 대신 3x3 크기의 커널을 사용하고 스트라이드를 2로 설정하여, 풀링이 겹치게 하였다. 이렇게 한 결과, top-1 error 는 0.3, top-5 erorr는 0.4 정도 성능 개선이 있었다. \n",
    "  \n",
    "5. Data Augmentation \n",
    "\n",
    " AlexNet에서는 과적합 문제를 방지하기 위해서, 아래에서 설명할 Dropout과 함께 Data Augmentation 을 사용했다. \n",
    "  1. 224x224로 잘라낸 이미지 그리고 원데이터를 좌우반전한 이미지 \n",
    "     - AlexNet에서는 Data Augmentation을 위해 원데이터와 원데이터를 좌우반전한 이미지에서 임의로 224x224 이미지를 추출하여 사용했다.(원 데이터의 크기는 다양했다.) 이렇게 해서 1개의 이미지로 2048개의 이미지를 만들어낼 수 있었다. 테스트 시에는 이미지에서 상하좌우 중앙 의 5개 이미지와 이를 반전한 5개 이미지 총 10장에 대한 예측치의 평균을 사용했다. \n",
    "  2. 학습 이미지로 부터 RGB값을 변화\n",
    "     - 모든 학습 이미지의 픽셀값에 대해 PCA를 수행하고 여기에 평균 0 표준편차 0.1의 정규분포에서 샘플링한 값($\\alpha$)을 곱해주어 원래 픽셀에 더해줌으로써 다양한 이미지를 얻을 수 있었다. \n",
    "     $$I_{xy} = [I_{xy}^R, I_{xy}^G, I_{xy}^B] + [v_1, v_2, v_3][\\alpha_1\\lambda_1, \\alpha_2\\lambda_2, \\alpha_2\\lambda_2]^T$$\n",
    "     \n",
    "6. Dropout \n",
    "\n",
    " Dropout은 Fully Connected layers 의 앞 두 단계에서 사용되었다. Dropout이 없을 때 보다, 수렴하는 시간은 느리지만, 과적합 문제를 극복할 수 있었다고 한다. \n",
    " \n",
    "7. 최적화 과정 \n",
    "\n",
    "   * Stochastic Gradient Descent \n",
    "    - batch size = 128 \n",
    "    - momentum = 0.9\n",
    "    - weight decay = 0.0005\n",
    "    - learning rate = 0.01 ($\\epsilon$)\n",
    "    $$v_{i+1} = 0.9v_i - 0.0005 \\epsilon w_i - \\epsilon \\dfrac{\\partial{L}}{\\partial{w_i}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "68a423b32bfa461b9a1a0e5e684d00a8"
   },
   "source": [
    "## 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "596d332132bc4ddeb00a5283cc757646"
   },
   "source": [
    "Keras의 Local response normalization(LRN) 명령이 없어졌다. 그래서 다음과 같이 직접 개발하여 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "school_cell_uuid": "edbdc7cb44574f77bf4a016392d0cf8b"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Lambda\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.layers import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "school_cell_uuid": "ec4b4539108d4e3a8996911d0117b018"
   },
   "outputs": [],
   "source": [
    "class LocalResponseNormalization(Layer):\n",
    "\n",
    "    def __init__(self, n=5, alpha=1e-4, beta=0.75, k=2, **kwargs):\n",
    "        self.n = n\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.k = k\n",
    "        super(LocalResponseNormalization, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.shape = input_shape\n",
    "        super(LocalResponseNormalization, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        _, r, c, f = self.shape \n",
    "        squared = K.square(x)\n",
    "        pooled = K.pool2d(squared, (self.n, self.n), strides=(1,1), padding=\"same\", pool_mode='avg')\n",
    "        summed = K.sum(pooled, axis=3, keepdims=True)\n",
    "        averaged = self.alpha * K.repeat_elements(summed, f, axis=3)\n",
    "        denom = K.pow(self.k + averaged, self.beta)\n",
    "        return x / denom \n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "school_cell_uuid": "bb8a15736b1c429b9b201e5021dbb250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 56, 56, 96)        34944     \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 56, 56, 256)       614656    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 56, 56, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 384)       885120    \n",
      "_________________________________________________________________\n",
      "local_response_normalization (None, 27, 27, 384)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,378,344\n",
      "Trainable params: 62,378,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (224, 224, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(96, (11, 11), strides=4,\n",
    "                 padding='same', input_shape=input_shape))\n",
    "model.add(Conv2D(256, (5, 5), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(LocalResponseNormalization(input_shape=model.output_shape[1:]))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Conv2D(384, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1000, activation='softmax'))\n",
    "\n",
    "optimizer = optimizers.SGD(lr=0.01, decay=5e-5, momentum=0.9)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}