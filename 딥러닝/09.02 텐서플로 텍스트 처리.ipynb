{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "d422edb7ee244ed382bdfe2475899a4d"
   },
   "source": [
    "## 텐서플로 텍스트 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "6c31e2883f5c42ab813b534b60f5ce2b"
   },
   "source": [
    "이 절에서는 텐서플로가 제공하는 텍스트 처리 기능을 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "a0e4b3bb9d034ba18be4465bc8e53a94"
   },
   "source": [
    "### `tf.keras.utils.get_file` 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "4bb7ab3c356f4a119d5121199f544eae"
   },
   "source": [
    "`tf.keras.utils.get_file` 함수는 인터넷의 파일을 로컬 컴퓨터의 홈 디렉토리 아래 `.keras/datasets` 디렉토리로 다운로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "school_cell_uuid": "efe5cc1b52f8417bb42ee6a3fb807112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dockeruser/.keras/datasets/butler.txt'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/data/illiad/butler.txt'\n",
    "text_path = tf.keras.utils.get_file(\"butler.txt\", origin=url)  \n",
    "text_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "55d84a28556c4614b5e1156f471be1ac"
   },
   "source": [
    "### `tf.data.TextLineDataset` 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "7bb982ab1ff94ca0af1dbfdbffb34641"
   },
   "source": [
    "`tf.data.TextLineDataset` 클래스는 텍스트 파일로부터 라인을 하나씩 추출하는 데이터셋이다. 위에서 다운로드받은 텍스트 파일을 `tf.data.TextLineDataset` 클래스 객체로 만들어 3줄만 출력하면 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "school_cell_uuid": "f7b890652b7741379bcab992569fe560"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\xef\\xbb\\xbfSing, O goddess, the anger of Achilles son of Peleus, that brought', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "ds_file = tf.data.TextLineDataset(text_path)\n",
    "for x in ds_file.take(1):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "984580190d384e7ebb7e98267b1abd98"
   },
   "source": [
    "### `tfds.features.text.Tokenizer ` 토크나이저"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "de84f8d8fa7f4c47b238193702eaf073"
   },
   "source": [
    "텐서플로 tensorflow_datasets 패키지(이하 tfds 패키지)의 feature.text 서브패키지는 텍스트 데이터를 처리할 수 있는 기능을 제공한다. 그 중의 하나가 `tfds.features.text.Tokenizer` 토크나이저다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "school_cell_uuid": "732e767335764812a57c870f585550e3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sing',\n",
       " 'O',\n",
       " 'goddess',\n",
       " 'the',\n",
       " 'anger',\n",
       " 'of',\n",
       " 'Achilles',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Peleus',\n",
       " 'that',\n",
       " 'brought']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "tokens = tokenizer.tokenize(x.numpy())\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "420161c3c7e245759b1bd95160c27da2"
   },
   "source": [
    "전체 문서를 토큰화하여 어휘목록(vocabulary)을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "school_cell_uuid": "bc40e872cfd94563bc6ac7bb89a37e6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7811"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_set = set()\n",
    "for text_tensor in ds_file:\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "79f3e4f7621f448b8f5a5f383914ba38"
   },
   "source": [
    "### `tfds.features.text.TokenTextEncoder ` 인코더"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "school_cell_uuid": "4d713db0676f4eccaedc089f9744cc04"
   },
   "source": [
    "`tfds.features.text.TokenTextEncoder ` 인코더는 토큰들을 숫자로 변환한다. 변환할 때는 `encode()` 메서드를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "school_cell_uuid": "b11f8c4b71c844c3be5b9f9bed564ecd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4104, 3644, 4170, 4965, 5838, 5295, 1764, 533, 5295, 7620, 5680, 7393]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "encoder.encode(x.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}