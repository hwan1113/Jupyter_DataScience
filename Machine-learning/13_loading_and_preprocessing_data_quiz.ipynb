{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "try:\n",
    "    # %tensorflow_version only exists in Colab.\n",
    "    %tensorflow_version 2.x\n",
    "    !pip install -q -U tfx==0.21.2\n",
    "    print(\"You can safely ignore the package incompatibility errors.\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# TensorFlow ≥2.0 is required\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "assert tf.__version__ >= \"2.0\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"data\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Exercise: Load the Fashion MNIST dataset (introduced in Chapter 10); split it into a training set, a validation set, and a test set; shuffle the training set; and save each dataset to multiple TFRecord files. Each record should be a serialized Example protobuf with two features: the serialized image (use tf.io.serialize_tensor() to serialize each image), and the label. Note: for large images, you could use tf.io.encode_jpeg() instead. This would save a lot of space, but it would lose a bit of image quality ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(len(X_train))\n",
    "valid_set = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "test_set = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_example(image, label):\n",
    "    image_data = tf.io.serialize_tensor(image)\n",
    "    return Example(\n",
    "        features=Features(\n",
    "            feature={\n",
    "                \"image\":Feature(bytes_list = BytesList(value=[image_data.numpy()])),\n",
    "                \"label\":Feature(int64_list = Int64List(value=[label.numpy()]))\n",
    "            }))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features {\n",
      "  feature {\n",
      "    key: \"image\"\n",
      "    value {\n",
      "      bytes_list {\n",
      "        value: \"\\010\\004\\022\\010\\022\\002\\010\\034\\022\\002\\010\\034\\\"\\220\\006\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000\\000\\rI\\000\\000\\001\\004\\000\\000\\000\\000\\001\\001\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\003\\000$\\210\\177>6\\000\\000\\000\\001\\003\\004\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000f\\314\\260\\206\\220{\\027\\000\\000\\000\\000\\014\\n\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\233\\354\\317\\262k\\234\\241m@\\027M\\202H\\017\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\000E\\317\\337\\332\\330\\330\\243\\177yz\\222\\215X\\254B\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\001\\001\\000\\310\\350\\350\\351\\345\\337\\337\\327\\325\\244\\177{\\304\\345\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\267\\341\\330\\337\\344\\353\\343\\340\\336\\340\\335\\337\\365\\255\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\301\\344\\332\\325\\306\\264\\324\\322\\323\\325\\337\\334\\363\\312\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\001\\003\\000\\014\\333\\334\\324\\332\\300\\251\\343\\320\\332\\340\\324\\342\\305\\3214\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\006\\000c\\364\\336\\334\\332\\313\\306\\335\\327\\325\\336\\334\\365w\\2478\\000\\000\\000\\000\\000\\000\\000\\000\\000\\004\\000\\0007\\354\\344\\346\\344\\360\\350\\325\\332\\337\\352\\331\\331\\321\\\\\\000\\000\\000\\001\\004\\006\\007\\002\\000\\000\\000\\000\\000\\355\\342\\331\\337\\336\\333\\336\\335\\330\\337\\345\\327\\332\\377M\\000\\000\\003\\000\\000\\000\\000\\000\\000\\000>\\221\\314\\344\\317\\325\\335\\332\\320\\323\\332\\340\\337\\333\\327\\340\\364\\237\\000\\000\\000\\000\\000\\022,Rk\\275\\344\\334\\336\\331\\342\\310\\315\\323\\346\\340\\352\\260\\274\\372\\370\\351\\356\\327\\000\\0009\\273\\320\\340\\335\\340\\320\\314\\326\\320\\321\\310\\237\\365\\301\\316\\337\\377\\377\\335\\352\\335\\323\\334\\350\\366\\000\\003\\312\\344\\340\\335\\323\\323\\326\\315\\315\\315\\334\\360P\\226\\377\\345\\335\\274\\232\\277\\322\\314\\321\\336\\344\\341\\000b\\351\\306\\322\\336\\345\\345\\352\\371\\334\\302\\327\\331\\361AIju\\250\\333\\335\\327\\331\\337\\337\\340\\345\\035K\\314\\324\\314\\301\\315\\323\\341\\330\\271\\305\\316\\306\\325\\360\\303\\343\\365\\357\\337\\332\\324\\321\\336\\334\\335\\346C0\\313\\267\\302\\325\\305\\271\\276\\302\\300\\312\\326\\333\\335\\334\\354\\341\\330\\307\\316\\272\\265\\261\\254\\265\\315\\316s\\000z\\333\\301\\263\\253\\267\\304\\314\\322\\325\\317\\323\\322\\310\\304\\302\\277\\303\\277\\306\\300\\260\\234\\247\\261\\322\\\\\\000\\000J\\275\\324\\277\\257\\254\\257\\265\\271\\274\\275\\274\\301\\306\\314\\321\\322\\322\\323\\274\\274\\302\\300\\330\\252\\000\\002\\000\\000\\000B\\310\\336\\355\\357\\362\\366\\363\\364\\335\\334\\301\\277\\263\\266\\266\\265\\260\\246\\250c:\\000\\000\\000\\000\\000\\000\\000\\000\\000(=,H)#\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\\000\"\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "  feature {\n",
      "    key: \"label\"\n",
      "    value {\n",
      "      int64_list {\n",
      "        value: 9\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for image, label in valid_set.take(1):\n",
    "    print(create_example(image, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import ExitStack\n",
    "\n",
    "def write_tfrecords(name, dataset, n_shards=10):\n",
    "    paths = [\"{}.tfrecord-{:05d}-of-{:05d}\".format(name, index, n_shards)\n",
    "            for index in range(n_shards)]\n",
    "    with ExitStack() as stack:\n",
    "        writers = [stack.enter_context(tf.io.TFRecordWriter(path))\n",
    "                  for path in paths]\n",
    "        for index, (image, label) in dataset.enumerate():\n",
    "            shard = index % n_shards\n",
    "            example = create_example(image, label)\n",
    "            writers[shard].write(example.SerializeToString())\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filepaths = write_tfrecords(\"my_fashion_mnist.train\", train_set)\n",
    "valid_filepaths = write_tfrecords(\"my_fashion_mnist.valid\", valid_set)\n",
    "test_filepaths = write_tfrecords(\"my_fashion_mnist.test\", test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Exercise: Then use tf.data to create an efficient dataset for each set. Finally, use a Keras model to train these datasets, including a preprocessing layer to standardize each input feature. Try to make the input pipeline as efficient as possible, using TensorBoard to visualize profiling data. ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tfrecord):\n",
    "    feature_descriptions = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string, default_value=\"\"),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(tfrecord, feature_descriptions)\n",
    "    image = tf.io.parse_tensor(example[\"image\"], out_type=tf.uint8)\n",
    "    image = tf.reshape(image, shape=[28, 28])\n",
    "    return image, example[\"label\"]\n",
    "\n",
    "def mnist_dataset(filepaths, n_read_threads=5, shuffle_buffer_size=None,\n",
    "                 n_parse_threads=5, batch_size=32, cache=True):\n",
    "    dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=n_read_threads)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    \n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls = n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = mnist_dataset(train_filepaths, shuffle_buffer_size=60000)\n",
    "valid_set = mnist_dataset(train_filepaths)\n",
    "test_set = mnist_dataset(train_filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for X, y in train_set.take(1):\n",
    "    for i in range(5):\n",
    "        plt.subplot(1, 5, i + 1)\n",
    "        plt.imshow(X[i].numpy(), cmap=\"binary\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(str(y[i].numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MapDataset' object has no attribute 'as_numpy_iterator'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-52abc8355e58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msample_image_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n\u001b[0m\u001b[0;32m     18\u001b[0m                                axis=0).astype(np.float32)\n\u001b[0;32m     19\u001b[0m \u001b[0mstandardization\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MapDataset' object has no attribute 'as_numpy_iterator'"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "class Standardization(keras.layers.Layer):\n",
    "    def adapt(self, data_sample):\n",
    "        self.means_ = np.mean(data_sample, axis=0, keepdims=True)\n",
    "        self.stds_ = np.std(data_sample, axis=0, keepdims=True)\n",
    "    def call(self, inputs):\n",
    "        return (inputs - self.means_) / (self.stds_ + keras.backend.epsilon())\n",
    "\n",
    "standardization = Standardization(input_shape=[28, 28])\n",
    "\n",
    "sample_image_batches = train_set.take(100).map(lambda image, label:image)\n",
    "sample_images = np.concatenate(list(sample_image_batches.as_numpy_iterator()),\n",
    "                               axis=0).astype(np.float32)\n",
    "standardization.adapt(sample_images)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    standardization,\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
